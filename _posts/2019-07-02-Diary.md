---
layout: post
title: "RTB 관련  자료"
categories: [AdTech]
---

Real-Time Bidding 관련 자료

[How This Research By Alibaba Group Has Used Reinforcement Learning To Change Real-Time Bidding](https://www.analyticsindiamag.com/how-this-research-by-alibaba-group-has-used-reinforcement-learning-to-change-real-time-bidding/)
<br>
[Real-Time Bidding by Reinforcement Learningin Display Advertising](https://arxiv.org/pdf/1701.02490.pdf)
<br>
[Display Advertising with Real-Time Bidding (RTB) and Behavioural Targeting](https://arxiv.org/pdf/1610.03013.pdf)
<br>
[Learning from the RTB market](https://geeks.jampp.com/data-science/learning-rtb/)
<br>
[Learning, Prediction and Optimization in Real-Time Bidding based Display Advertising](https://www.slideshare.net/JianXu17/learning-prediction-and-optimization-in-realtime-bidding-based-display-advertising)

## One-hot Encoding
### 1. Why one-hot encoding?
* categorical data는 제한된 갯수의 label 정보를 가지고 있다.  -> convert categorical data in the form of numeric values
* ML 알고리즘 중 상당수는 input과 output이 숫자형으로 되어있기를 요구한다.
* 차원축소가 가능하게 만들어준다

-> 내가 주로 쓰던 방법은 Integer encoding이였지만, 이는 내가 다뤘던 데이터는 rarely showed categorical values

* train set과 test set의 데이터 구성이 다를 수 있음(ex. train시에는 있었던 변수인데 test시에는 빠져있는 경우)

* sklearn - OneHotEncoder
 - LabelEncoder - transform strings to integer labels
 - build a dictionary that will map a feature to its encoder
 - one hot encoder does not support passing the list of categorical features by their names but only by their indexes
* there are some other one-hot encoder or hashing tricks


### 2. Difference between Hashing trick
* Hashing is like OneHot but fewer dimensions, some info loss due to collision. Nominal, ordinal

* Feature hashing is a very cool technique to represent categories in a “one hot encoding style” as a sparse matrix but with a much lower dimensions. In feature hashing we apply a hashing function to the category and then represent it by its indices.

* Pros:
  1. It is low dimensional thus it is very efficient in processing time and memory, it can be computed with online learning because as opposed to one hot encoding we don’t need to go over all the data and build a dictionary of all possible categories and their mapping and it is not affected by new kinds of categories.

* Cons:
  1. Hashing functions sometimes have collision so if H(New York) = H(Tehran) the model can’t know what city were in the data. There are some sophisticated hashing function that try to reduce the number of collision but anyway, studies have shown that collisions usually doesn’t affect significantly on the models performance.
  2. Hashed features are not interpretable so doing things like feature importance and model debugging is very hard.


### 3. Data Preprocessing
  * numerical : leave it alone, or take logarithm(depends on the data)
  * categorical : one-hot, hashing tricks etc.


### 4 Modeling:
  * Linear Models
      - Logistic Regression with SGD learning or with FTRL
      - Online Bayesian Probit Regression
  * Non-linear Models:
      - Gradient Boosting Decision Tree
      - Field-aware Factorization Machine
      - Ensemble
      - DNN
      - Markov Decision Process(more into Sponsored-Search RTB)
