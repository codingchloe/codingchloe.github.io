---
layout: post
title: "기초통계학(4)- Undersampling, Oversampling 그리고 평가지표"
categories: [Statistics]
---
실무에서 데이터를 다루 다 보면 데이터 불균형을 꽤 잦게 마주하게 된다. <br>
데이터 불균형이란, 우리가 만일 맞추고자 하는 목표, target을 발생할 경우(1)/발생하지 않는 경우(0)으로 나누었을 때, 발생할 경우와 발생하지 않을 경우의 비율이 현저히 차이가 나는 케이스를 말한다. 예를 들어 은행의 사기 거래, 희귀 질병 발견 여부 등이 있다. 데이터가 불균형인 상태로 그대로 모델 평가를 시작한다면, 당연히 모델은 더 큰 집단에 대해 치우쳐져 있는 모델을 만들 것이다. <br>
이 문제를 해결하기 위해 다수였던 발생하지 않는 경우(0)의 빈도 수를 줄이던지(<u>undersampling</u>), 발생할 경우(1)의 빈도 수를 늘리는(<u>oversampling</u>) 방법이 있다. 언더샘플링과 오버샘플링의 방법에도 랜덤으로 추출하냐, 앙상블 기법으로 비율을 고려하여 추출하냐, 새로운 데이터를 생성(SMOTE)하냐 등에 따라서 방법은 다양하다. 어떻게 샘플링하는지는 데이터 속성에 따라서 경험적으로 선택하면 되고, 굳이 하나의 글로 쓴 이유는 이 작업이 모델 결과로는 큰 차이를 가져올 수 있기 때문이다. 나도 꽤 오랜 시간동안 오버샘플링, 언더샘플링 이론만 듣고, 큰 의심하지 않고 부서에서 줄곧 하던대로 샘플링 비율(예를 들면 50:50)을 설정했다. 데이터 성격 자체가 크게 상관이 없었긴 하지만 그런가보다 하고 실행하였다는 것이 부끄러운 일이다.
<br>
또 한 가지 언급할 부분은 이렇게 데이터의 불균형이 있을 경우, 성능 지표는 Lift, F1-measure 등과 같은 지표를 써야 목적에 맞는 측정을 할 수 있다. 이 지표들은 데이터 불균형으로 그 의미가 희석될 수 있는 accuracy를 보는 것이 아니라, 내가 고른 상위 1부터 100개까지의 레코드 중 얼마나 정답을 맞추는지, 또는 false positive와 false negative를 종합한 결과를 보여주는 지표이다. 모델이 실제로는 잘 맞추지 못하는 모델이여도 accuracy는 높게 나올 수 있기 때문이다.  
