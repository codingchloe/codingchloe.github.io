---
layout: post
title: "L1 vs. L2 Regularization"
categories: [DeepLearning]
---
앞선 [포스트](https://codingchloe.github.io/2018-09-25/L1-vs-L2-loss-function)에서는 L1 loss function과 L2 loss function을 다루었습다. 그러다보니 L1, L2 Regularization이라는 개념도 자연스럽게 연상이 되어, 이번 글에서는 Regularization에 대해 설명해보겠습니다.


## 0. Regularization(정규화)은 왜 하는 것일까?
학습되는 모델의 overfitting을 막기 위한 방법 중 하나가 regularization(정규화)입니다.
(참고 글: [Overfitting이란?](https://codingchloe.github.io/2018-09-26/Overfitting이란))


## 1. L1 Regularization
Regression 모델에서 L1 Regularization을 쓰는 모델은 Lasso 입니다.


## 2. L2 Regularization



*작성 중인 글입니다.*
