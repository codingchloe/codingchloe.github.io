---
layout: post
title: "기초통계학(2)- 회귀 모형별 용어/지표 정리"
categories: [Statistics]
---
다중선형회귀에 쓰이는 단어, 용어 위주로 기록을 남겼다. 

## 다중선형회귀

* 제곱근 평균제곱오차(root mean squared error, RMSE)
: 회귀 시 평균제곱오차의 제곱근. 회귀모형을 평가하는데 가장 널리 사용되는 측정 지표
* 잔차 표준오차(residual standard error, RSE)
: 평균제곱오차와 동일하지만 자유도에 따라 보정된 값(모수가 데이터 수가 아닌 자유도), 실무에서 선형회귀분석을 할 떄, RMSE와 RSE 차이는 매우 작다. 특히 빅데이터 분야에서는 더 그러하다.
* R 제곱(r-squared)
: 0에서 1까지의 모델 데이터의 변동률, 결정계수라고도 불림. 모델이 데이터에 얼마나 적합한지 평가하고자 할 때, 회귀분석을 설명하기 위한 용도로 활용. 높을수록 유의미.
* 수정 R 제곱(adjusted R-squared)
: 자유도를 고려한 R 제곱, 마찬가지로 일반 R제곱과 크게 다르지 않다.
* t 통계량(t-statistic)
: 계수의 표준오차로 나눈 예측변수의 계수. 모델에서 변수의 중요도를 비교하는 기준이 된다. <br>
t 통계량이 높을수록(p 값이 낮을수록) 예측변수는 더욱 유의미하다.
* 가중회귀
: 다른 가중치를 가진 레코드들을 회귀, 레코드별 특징이 다를 경우 활용
* 교차타당성검사(cross validation)
: 데이터 모수가 작을 때(train과 test set으로 나누기에도 어려운 작은 데이터 집합) 주로 쓰는 방법<br>
k 다중 교차타당성검사(k-fold cross-validation)이 가장 기본적인 방법인데,
<br>
1. 1/k의 데이터를 홀드아웃 샘플로 따로 떼어놓는다.
2. 남아 있는 데이터로 모델을 훈련시킨다.
3. 모델을 1/k 홀드아웃에 적용(점수를 매김)하고 필요한 모델 평가 지표를 기록한다.
4. 데이터의 첫 번째 1/k을 복원하고 다음 1/k(앞에서 선택했던 레코드는 제외)을 따로 보관한다.
5. 2~3 단계를 반복한다.
6. 모든 레코드가 홀드아웃 샘플로 사용될 때까지 반복한다.
7. 모델 평가 지표들을 평균과 같은 방식으로 결합한다.

### 변수를 추가하면 항상 RMSE는 감소하고 R-squared는 증가한다.
### 이를 보완할 수 있는, 모델에 항을 추가할수록 불이익을 주는, AIC라는 측정지표가 있다. 그외 BIC, 멜로즈 C가 있다.  

* AIC(Akaike's information criteria)
: 모델에 k 개의 변수를 추가한다면, 2k만큼 불이익을 받게 된다. AIC 값이 낮을수록 적합한 모델
* 전진선택(forward selectoin), 후진선택(backward selection), all-possible selection
: 모델에 추가할 변수 순서 방향
* 벌점 회귀(penalized regression)
: 위에 언급한 변수 선택 방법의 의도와 유사하지만, 예측변수를 과정 중 완전히 제거하는 대신, <u>계수의 크기를 감소</u>시키거나 경우에 따라 거의 0으로 만들어 벌점을 적용한다. (ex. 능형회귀(ridge), 라소(lasso), 향후 머신러닝 편에서 언급 예정)
* 더빈-왓슨 통계량
: 시계열 데이터를 다루는 회귀분석에서 유의미한 자기상관(autocorrelation)이 있는지 탐지
